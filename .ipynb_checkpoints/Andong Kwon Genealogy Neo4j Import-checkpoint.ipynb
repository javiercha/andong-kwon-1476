{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe8bbb9",
   "metadata": {},
   "source": [
    "## The Andong Kwŏn Genealogy of 1476: Neo4j Bulk-Import Notebook\n",
    "\n",
    "This notebook bulk imports the *Andong Kwŏn Genealogy of 1476* (*Andong Kwŏn ssi Sŏnghwabo* 安東權氏成化譜) node and edge tables into a Neo4j database, which enables the exexcution of robust graph queries and machine-assisted exploration of this valuable historical source.\n",
    "\n",
    "---\n",
    "\n",
    "### Overview of notebook functions\n",
    "\n",
    "1. **Load source files**  \n",
    "   * `tsv/andongkwon_1476_nodes.tsv` (node attribute table)  \n",
    "   * `tsv/andongkwon_1476_edges.tsv` (edge list)\n",
    "\n",
    "2. **Unicode normalization**  \n",
    "   All string fields are normalized using **NFKC** to eliminate hidden duplicates caused by visually similar characters mapped onto distinct Unicode values.\n",
    "\n",
    "3. **Index creation**  \n",
    "   Adds indexes to optimize graph traversal and improve performance during data import.\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "The notebook requires an active Neo4j instance:\n",
    "\n",
    "1. Install Neo4j Desktop or Neo4j Server (community or enterprise edition works equally well).\n",
    "2. Edit the default address `bolt://localhost:7687` according to your configuration, if necessary.\n",
    "3. Check the default username `neo4j` and insert your own password in the code cell that initializes the driver. Never commit this credential to a public repository.\n",
    "4. The TSV files are read directly from the `tsv/` folder in this GitHub repository.\n",
    "\n",
    "---\n",
    "\n",
    "### Notes\n",
    "\n",
    "* See `Andong Kwon Genealogy Inspection.ipynb` for page-by-page visualizations of the genealogy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a4cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2447d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb075e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted nodes: 7580.\n",
      "Created nodes: 7424.\n",
      "Created relationships: 8703.\n",
      "Merged nodes: 3.\n",
      "Merged relationships: 62.\n",
      "Updated chains: 9954.\n",
      "Updated nodes: 12014.\n",
      "169 choronym value(s) converted from one-item lists to strings.\n"
     ]
    }
   ],
   "source": [
    "# Session 1: Delete all existing nodes and relationships.\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH (m) DETACH DELETE (m)\n",
    "    \"\"\")\n",
    "    print(f\"Deleted nodes: {result.consume().counters.nodes_deleted}.\")\n",
    "\n",
    "# Session 2: Load nodes from TSV.\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM 'https://raw.githubusercontent.com/javiercha/andong-kwon-1476/refs/heads/main/tsv/andongkwon_1476_nodes.tsv' as row FIELDTERMINATOR '\\t'\n",
    "        CREATE (m:Person) set m+=row\n",
    "        RETURN count(m)\n",
    "    \"\"\")\n",
    "    for record in result:\n",
    "        print(f\"Created nodes: {record[0]}.\")\n",
    "\n",
    "# Sessions 3 and 4: Create indexes on biog_id and choronym.\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        CREATE INDEX IF NOT EXISTS FOR (m:Person) ON (m.biog_id)\n",
    "    \"\"\")\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        CREATE INDEX IF NOT EXISTS FOR (m:Person) ON (m.biog_id)\n",
    "    \"\"\")\n",
    "\n",
    "# Session 5: Load edges from TSV and create relationships.\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM 'https://raw.githubusercontent.com/javiercha/andong-kwon-1476/refs/heads/main/tsv/andongkwon_1476_edges.tsv' AS row FIELDTERMINATOR '\\t'\n",
    "        MERGE (source:Person {biog_id: row.source})\n",
    "          ON CREATE SET source.name = row.source_name,\n",
    "                        source.vol = toInteger(row.vol),\n",
    "                        source.leaf = toInteger(row.leaf),\n",
    "                        source.side = row.side,\n",
    "                        source.page = row.page,\n",
    "                        source.page2024 = row.page2024,\n",
    "                        source.reference = row.reference\n",
    "        MERGE (target:Person {biog_id: row.target})\n",
    "          ON CREATE SET target.name = row.target_name,\n",
    "                        target.vol = toInteger(row.vol),\n",
    "                        target.leaf = toInteger(row.leaf),\n",
    "                        target.side = row.side,\n",
    "                        target.page = row.page,\n",
    "                        target.page2024 = row.page2024,\n",
    "                        target.reference = row.reference\n",
    "        WITH source, target, row,\n",
    "             CASE\n",
    "                 WHEN source.choronym = '安東 權' AND target.choronym = '安東 權' AND row.type = 'HAS_SON' THEN 'HAS_SON_AK'\n",
    "                 ELSE row.type + '_SSB'\n",
    "             END as relationshipType\n",
    "        CALL apoc.create.relationship(source, relationshipType, {\n",
    "            child_order: toInteger(row.child_order),\n",
    "            wife_note: row.wife_note,\n",
    "            reference: row.reference,\n",
    "            vol: toInteger(row.vol),\n",
    "            leaf: toInteger(row.leaf),\n",
    "            side: row.side\n",
    "        }, target) YIELD rel\n",
    "        RETURN count(rel)\n",
    "    \"\"\")\n",
    "    for record in result:\n",
    "        print(f\"Created relationships: {record[0]}.\")\n",
    "\n",
    "# Session 6: Merge duplicate nodes.\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH (n:Person)\n",
    "        WITH n.biog_id AS biogId, collect(n) AS nodesToMerge\n",
    "        WHERE size(nodesToMerge) > 1\n",
    "        CALL apoc.refactor.mergeNodes(nodesToMerge, {\n",
    "            properties: 'combine'\n",
    "        }) YIELD node\n",
    "        RETURN count(node) AS mergedNodesCount\n",
    "    \"\"\")\n",
    "    for record in result:\n",
    "        print(f\"Merged nodes: {record[0]}.\")\n",
    "\n",
    "# Session 7: Merge duplicate relationships.\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH (source)-[r]->(target)\n",
    "        WITH source, target, collect(r) AS rels, type(r) AS relType, COUNT(r) AS count\n",
    "        WHERE count > 1\n",
    "        CALL apoc.refactor.mergeRelationships(rels, {mergeRels: true}) YIELD rel\n",
    "        RETURN count(rel) AS mergedRelationshipCount\n",
    "    \"\"\")\n",
    "    for record in result:\n",
    "        print(f\"Merged relationships: {record[0]}.\")\n",
    "        \n",
    "# Session 8: Update missing choronym data in HAS_SON chains up to 5 node distances.\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\" \n",
    "        MATCH path = (n)-[r*1..5]-(m)\n",
    "        WHERE all(rel IN relationships(path) WHERE type(rel) STARTS WITH 'HAS_SON')\n",
    "          AND any(x IN nodes(path) WHERE x.choronym IS NOT NULL)\n",
    "          AND any(x IN nodes(path) WHERE x.choronym IS NULL)\n",
    "\n",
    "        WITH\n",
    "             nodes(path)                                                  AS chain,\n",
    "             [x IN nodes(path) WHERE x.choronym IS NOT NULL]              AS filled,\n",
    "             [x IN nodes(path) WHERE x.choronym IS NULL]                  AS empty\n",
    "\n",
    "        WITH\n",
    "             chain, empty,\n",
    "             apoc.coll.toSet(\n",
    "                 apoc.coll.flatten(\n",
    "                     [x IN filled | x.choronym]\n",
    "                 )\n",
    "             ) AS uniqChoronym\n",
    "\n",
    "        UNWIND empty AS node\n",
    "        SET   node.choronym = uniqChoronym\n",
    "\n",
    "        WITH chain, node\n",
    "        RETURN count(DISTINCT chain) AS updatedChainCount,\n",
    "               count(node)           AS updatedNodeCount;\n",
    "    \"\"\")\n",
    "    for record in result:\n",
    "        print(f\"Updated chains: {record['updatedChainCount']}.\")\n",
    "        print(f\"Updated nodes: {record['updatedNodeCount']}.\")\n",
    "\n",
    "# Session 10: If a choronym is a list with only one entry, convert to string.\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH (n)\n",
    "        WHERE n.choronym IS NOT NULL\n",
    "          AND apoc.convert.toJson(n.choronym) STARTS WITH '['\n",
    "          AND size(n.choronym) = 1\n",
    "        WITH n, n.choronym[0] AS newValue       // extract the lone entry\n",
    "        SET  n.choronym = newValue              // list → scalar\n",
    "        RETURN count(n) AS conversions\n",
    "    \"\"\").single()[\"conversions\"]\n",
    "\n",
    "print(f\"{result} choronym value(s) converted from one-item lists to strings.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
